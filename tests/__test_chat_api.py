# -*- coding: utf-8 -*-
'''
Filename: server.py
Author: Michel Levy Provencal
Description: This Flask application handles two types of chat requests: streaming chat and standard chat. If no 'model' parameter is specified, it defaults to "gpt-4".

Modifications: The code has been updated to include a default model if no 'model' parameter is specified in the request.
'''

# Import a module to generate chat responses
import generatechatcompletion

# Import os module for interacting with the operating system
import os


consigne = "Voici en vrac une liste de notes, tweets, articles identifiés cette semaine. A partir de ces éléments construire une newsletter qui les mets en forme et cite bien les URL afin que le lecteur puisse les consulter "
texte = "1/ Les fondamentaux de la prédiction avec des réseaux de neurones.Linear Regression clearly Explained! Linear Regression models relationship between a dependant variable (y) & two or more independent variables (x1, x2 ...) For the sake of simplicity we discuss linear regression with a single independent variable. Mathematical Representation: y=mx+c where: - y is the dependent variable - x is the independent variable - m is the slope of the line - c is the y intercept Cost Function: The goal is to find the best values for m and c that minimize the error between the predicted values & the actual values for all data points. This is how the cost function looks, a mean squared error: MSE= 1/N∑(yi−(m*xi+c))**2 Where: - N is the number of data points. - yi is the actual value for the ith data point. - mxi+c is the predicted value for the ith data point.How it works (Optimisation) To minimize the MSE, we can use gradient descent. The basic idea is to: - Start with some initial value of m & c - Compute the gradient of the MSE w.r.t. both m & c. - Update m & c in the direction of the negative gradient.Implementation from Scratch: Now that we understand how things work it's fairly simple to implement linear regression in Python! Check this outThat's a wrap! If you interested in: - Python - ML/MLOps - CV/NLP - LLMs - AI Engineering Find me →@akshay_pachaarEveryday, I share tutorials on above topics! I also write a weekly Newsletter on AI Engineering, link in the next tweet! Cheers!!https://twitter.com/akshay_pachaar/status/17146199209553469952/ Une nouvelle formation sur l'IA générativeI’m teaching a new course: Generative AI for Everyone, which is coming soon! Learn how Generative AI works, how to use it in professional or personal settings, and how it will affect jobs, businesses and society. This course is accessible to everyone, and assumes no prior coding or AI experience. Please join the waitlist to be among the first to know when it goes live!https://t.co/89tH4Sk0H83/ Meta GPT : Impressive. MetaGPT is about to reach 30,000 stars on Github. It's a Multi-Agent Framework that can behave as an engineer, product manager, architect, project managers. With a single line of text it can output the entire process of a software company along with carefully orchestrated SOPs: ▸ Data structures ▸ APIs ▸ Documents ▸ User stories ▸ Competitive analysis ▸ Requirementshttps://github.com/geekan/MetaGPT4/ Meta et un model avancé de génération d'imagesBREAKING: META have developed a more advanced Generative AI model than SDXL for image generation! It's called Emu and it comes with a new technique called quality-tuning. I think we are going to hear a lot about it in the coming months! Here's everything you need to know: - It's beautiful: in human evaluations, Meta is saying that Emu is preferred 68.4% and 71.3% of the time for its visual appeal. - Dataset: pre-trained with a latent diffusion model on 1.1 billion image-text pairs - Curated fine-tuning: it has been fine-tuned with only a few thousand carefully selected high-quality images. Interesting Details - Quality over quantity: despite the common belief that models need large amounts of data to fine-tune, this work shows that using even a few thousand high-quality images can significantly improve the aesthetics of the generated images. - Connection with language models: the research highlights interesting parallels between tuning visual generative models and language models, meaning that the same strategies can be useful for both. Heads up, this is more important than it initially seems: we would be talking about the first real union between the technologies of the LLM and the diffusion models that could merge into one thing. And Meta is already using it! Did you see all the fuss about Meta's AI accounts based on celebrities like Kendall? Well, the images that these virtual avatars are sharing on Instagram are generated with this model. Where can I try it? Meta has not commented on this matter. But we are all eager to sink our teeth into it. That is, it's not possible to try it yet.https://twitter.com/i/web/status/17129679163064526595/ Microsoft autogenMicrosoft's Autogen is blowing up on Github. It's a framework that allows LLM agents to chat with each other to solve your tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. It's also a drop-in replacement of openai.Completion or openai.ChatCompletion as an enhanced inference API.https://github.com/microsoft/autogen6/ Moonvalley un nouveau générateur de videoMoonvalley is a groundbreaking new text-to-video generative AI modelCreate breathtaking cinematic & animated videos from simple text promptshttps://moonvalley.ai/7/ Launching Towards AI’s Free “Train & Fine-Tune LLMs for… – Towards AIhttps://towardsai.net/p/artificial-intelligence/launching-towards-ais-free-train-fine-tune-llms-for-production-courseTowards [AI](https://towardsai.net/p/machine-learning/differences-between-ai-and-machine-learning-1255b182fc6) is thrilled to announce the launch of the free and comprehensive course [Training and Fine-tuning Large Language Models (LLMs) for Production](https://learn.activeloop.ai/courses/llms), the second installment of the Gen [AI](https://towardsai.net/p/machine-learning/differences-between-ai-and-machine-learning-1255b182fc6) 360: Foundational Model Certification. This initiative was made possible thanks to the robust collaboration with [Activeloop](https://activeloop.ai/) and the [Intel Disruptor Initiative](https://www.intel.com/content/www/us/en/partner-alliance/membership/select-benefit/disruptors/overview.html) and is greatly supported by Lambda and Cohere.https://prod-files-secure.s3.us-west-2.amazonaws.com/bc30315f-1cde-4ad5-8ca0-91c82e27d26c/934bdf73-30c7-4637-9df1-f8832bcb13b3/0YDRwC4dzRr9dcEf6The course builds upon the success of our previous installment, the [LangChain and Vector Databases in Production course](https://learn.activeloop.ai/courses/langchain), with tens of thousands of course takers. It is designed as a mix of 9 high-level videos, 40+ self-paced text tutorials, and 10+ practical projects like training a model from scratch or fine-tuning models for financial or biomedical use cases. “We’ve designed the course to cut through the noise of the latest rapid advancements in the LLMs, distilling it into a strategic pathway to empower technical professionals and executives to navigate the world of LLMs with efficiency and production readiness in mind,” said [Louie Peters](mailto:louie@towardsai.net), CEO and Co-Founder of Towards AI.**Bridging Theoretical Knowledge with Practical Expertise for Production-Ready LLMs**“Training and Fine-tuning LLMs for Production” is designed to provide participants with deep, practical insights into the world of LLMs. It takes you on an exploration through the intricacies of training, fine-tuning, and implementing large language models in real-world business applications, ensuring that the knowledge imparted is readily applicable in professional settings. Participants will work on reinforcement learning from human feedback (RLHF) to improve an LLM, fine-tune a model on a business use case such as extracting disease-chemical relations from papers, or train an LLM from scratch.Targeting Python professionals, our modules guide learners through strategic compute utilization during model training or fine-tuning. They empower them to make sound choices in resource allocation and technique selection, ensuring state-of-the-art, cost-effective, and efficient model development.“LLMs offer tremendous potential. However, understanding their economic implications is crucial for enterprises considering their adoption. Companies need to understand the cost structure of training, fine-tuning, and productizing an LLM. This course represents a state-of-the-art blend of software like Deep Lake, LLM-optimized hardware, and groundbreaking Gen AI platforms that enable companies to train and fine-tune production-ready LLMs without breaking the bank”, said Davit Buniatyan, Activeloop CEO and Co-Founder.**Course Curriculum**- Introduction to LLMs: Exploring foundational LLM concepts- LLM Architecture: Diving into model architectures- Training LLMs: Data management and ensuring quality in [training data](https://towardsai.net/p/machine-learning/best-datasets-for-machine-learning-and-data-science-d80e9f030279) with Deep Lake and beyond. Strategies for effective model training and using Deep Lake for optimal data loading and compute utilization- Fine-tuning LLMs: Optimizing models for specific uses across business verticals (e.g. financial and biomedical)- Improving LLMs with RLHF: Applying reinforcement learning with human feedback to better LLM performance- Deploying LLMs: Strategies for real-world deployment with LLM-optimized compute- Advanced topics: Navigating through LLM ethics, scaling laws, model collapse, and future LLM training challengesThis course is a goldmine of knowledge for technical professionals, offering a deep dive into the intricacies of training and fine-tuning models, ensuring optimal resource utilization, and providing a hands-on experience through real-world projects and case studies.Tech executives, on the other hand, will find value in watching the available 1.5hrs of video content, understanding the strategic and economic aspects of implementing LLMs, and ensuring that their teams are not merely utilizing resources effectively but are also making informed, strategic decisions that align with organizational goals and ethical considerations.“I believe engineers and technology executives could greatly benefit from taking this course to stay at the forefront of AI,” said Arijit Bandyopadhyay, CTO — [Enterprise](https://sponsors.towardsai.net/) Analytics & AI, Head of Strategy — Cloud & [Enterprise](https://sponsors.towardsai.net/), DCAI Group at Intel Corporation. “Intel continues to be at the vanguard of AI and new technology adoption. This Foundational Model Certification could help better equip the next generation of innovators with what they need to succeed with [Generative AI](https://towardsai.net/ai/generative-ai) and Large Language Models. It could also contribute to the broader adoption of AI applications and solutions across various industries.”**Free Compute Credits, Enabled with the Support of Course Partners Cohere and Lambda**With the generous support of our partners, the qualifying candidates who successfully pass the required chapters will unlock exclusive access to Lambda and Cohere credits, facilitating a smoother and more resource-optimized learning journey. This course is not just a certification; it is a safeguard against unnecessary computational expenditures, a guarantee to optimize resource utilization, and a promise to implement LLMs in a state-of-the-art and financially sound manner.Seize the opportunity to be at the forefront of [Generative AI](https://towardsai.net/ai/generative-ai) and Large Language Models, and ensure your team navigates the complexities and potential of LLMs with strategic and economic proficiency. [Enroll in our course for free now](https://learn.activeloop.ai/courses/llms), and complete the required chapters to be among the qualifying participants to get the compute credits from our partners.https://towardsai.net/p/artificial-intelligence/launching-towards-ais-free-train-fine-tune-llms-for-production-course8/ Les LLM sont en train d'accélérer les applications de robotique à une vitesse folle. #RDV2025Can GPT-4 teach a robot hand to do pen spinning tricks better than you do?I'm excited to announce Eureka, an open-ended agent that designs reward functions for robot dexterity at super-human level. It’s like Voyager in the space of a physics simulator API!Eureka bridges the gap between high-level reasoning (coding) and low-level motor control. It is a “hybrid-gradient architecture”: a black box, inference-only LLM instructs a white box, learnable neural network. The outer loop runs GPT-4 to refine the reward function (gradient-free), while the inner loop runs reinforcement learning to train a robot controller (gradient-based).We are able to scale up Eureka thanks to IsaacGym, a GPU-accelerated physics simulator that speeds up reality by 1000x. On a benchmark suite of 29 tasks across 10 robots, Eureka rewards outperform expert human-written ones on 83% of the tasks by 52% improvement margin on average. We are surprised that Eureka is able to learn pen spinning tricks, which are very difficult even for CGI artists to animate frame by frame!Eureka also enables a new form of in-context RLHF, which is able to incorporate a human operator’s feedback in natural language to steer and align the reward functions. It can serve as a powerful co-pilot for robot engineers to design sophisticated motor behaviors.As usual, we open-source everything! Code: http://github.com/eureka-research/Eureka9/ Ce tweet est un signal faible d’une importance fondamentale pour l’évolution de l’IA.La prochaine étape (2025 - 2030) sera doter les LLM d’une incarnation. C’est à dire transformer les chatbots en robot physiques.Had a great TED AI Panel yesterday!My main point:LLMs need embodiment to unlock higher levels of intelligence. The stream of experience data through exploration & experiments will provide infinite tokens.Our current LLMs are the pre-training checkpoints for an embodied agent that learns causality, intuitive physics, and grounds its abstract knowledge through interacting with the world (virtual or physical). You can think of the world as an immersive generator of multimodal sensory signals.https://twitter.com/DrJimFan/status/171506783278508854110/ Génération d'avatars voix / videoRIEN dans cette vidéo n'est VRAI. Ni le texte du discours, Ni la voix, Ni la vidéo.Tout a été généré par des IA à partir d'une seule requête : Écrire un talk sur le thème des inégalités...Ca a pris une demi heure à réaliser de bout en bout. Et couté moins de 5 euros.On en est là !RDV dans 9 mois...En 15 ans, j'ai (co)écrit des centaines de talks ! Mais c'est la première fois que je collabore avec une IA pour ça et tout ce qu'il m'a fallu, c'est une seule phrase : Ecris moi un talk sur le thème des avatars pilotés par des IA. Voici le résultat #IA #StoryTellinghttps://twitter.com/mikiane/status/1714393255209570535"
system = "Une IA capable de rédiger du texte en prenant en compte un contexte et en s'appuyant sur celui ci pour répondre à des instructions."
model = "gpt-4"

generator_instance = generatechatcompletion.generate_chat_completion(consigne, texte, model)

# Itérer sur le générateur pour exécuter et obtenir les valeurs
for generated_text in generator_instance:
    print(generated_text)